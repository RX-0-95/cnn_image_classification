{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd01e176acbd42c1e3e7f101af43ec62a5c4debfebb92accde047567277d89b2ce2",
   "display_name": "Python 3.8.10 64-bit ('tf-gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,) int64\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "import gzip, shutil\n",
    "import os \n",
    "import data_utils as du \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import numpy as np \n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.pyplot import imread\n",
    "import matplotlib.pyplot as plt \n",
    "import platform\n",
    "import data_utils as du \n",
    "from cnn_model import *\n",
    "from solver import Solver\n",
    "import qunatize_resnet20 as q_res\n",
    "import quantize_layers as ql\n",
    "import tensorflow_hub as hub \n",
    "import quantize_util as qu \n",
    "import quantize_complier as qc \n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "plt.rcParams['figure.figsize'] = (15.0, 15.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "Data_folder = 'CIFAR10_Data'\n",
    "Data_fn = 'cifar-10-python'\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = du.get_CIFAR10_data(subtract_mean =True)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<quantize_layers.quantizeConv2D object at 0x7f983cac69a0>\n<quantize_layers.quantizeConv2D object at 0x7f983ca43cd0>\n<quantize_layers.quantizeConv2D object at 0x7f983cac6730>\n<quantize_layers.quantizeConv2D object at 0x7f983ca18d00>\n<quantize_layers.quantizeConv2D object at 0x7f97c87ae190>\n<quantize_layers.quantizeConv2D object at 0x7f9820243f70>\n<quantize_layers.quantizeConv2D object at 0x7f9820667340>\n<quantize_layers.quantizeConv2D object at 0x7f983d971550>\n<quantize_layers.quantizeConv2D object at 0x7f97c83aae80>\n<quantize_layers.quantizeConv2D object at 0x7f983d71c280>\n<quantize_layers.quantizeConv2D object at 0x7f982024eb80>\n<quantize_layers.quantizeConv2D object at 0x7f983d36a250>\n<quantize_layers.quantizeConv2D object at 0x7f98204fe640>\n<quantize_layers.quantizeConv2D object at 0x7f983d3b6bb0>\n<quantize_layers.quantizeConv2D object at 0x7f983da54b50>\n<quantize_layers.quantizeConv2D object at 0x7f988581dd90>\n<quantize_layers.quantizeConv2D object at 0x7f988582f190>\n<quantize_layers.quantizeConv2D object at 0x7f97c86afd00>\n<quantize_layers.quantizeConv2D object at 0x7f983da75130>\n<quantize_layers.quantizeDense object at 0x7f983d318250>\n"
     ]
    }
   ],
   "source": [
    "data_set = {\n",
    "    'train_data': X_train,\n",
    "    'train_label': y_train,\n",
    "    'val_data':X_val,\n",
    "    'val_label':y_val,\n",
    "}\n",
    "train_options = {\n",
    "    'optimizer': 'adam',\n",
    "    'lr': 0.001,\n",
    "    'epoch_num': 1,\n",
    "    'from_logits':True,\n",
    "    'save_dir': 'resnet20_model'\n",
    "}\n",
    "model_path = 'resnet20_model/trained_15'\n",
    "full_model = hub.KerasLayer(model_path,trainable=True)\n",
    "\n",
    "qunatizer = ql.ModelQunatize() \n",
    "model_q = q_res.Resnet20(qunatizer)\n",
    "qu.copy_weight(model_q,full_model)\n",
    "q_layers = model_q.get_quantizable_layers()\n",
    "for layer in q_layers:\n",
    "    print(layer)\n",
    "\n",
    "solver = Solver(model_q,data_set,train_options,save_model=False)\n",
    "\n",
    "data_shuffler = qc.DataShuffler(X_train, y_train,sample_size=1024)\n",
    "\n",
    "\n",
    "def train_fn(model,solver=solver):\n",
    "    solver = Solver(model,data_set,train_options,\n",
    "                    save_model=False,verbose=False,\n",
    "                    plot_graph=False)\n",
    "    return solver.train(iter=int(5000/32))\n",
    "\n",
    "def test_fn(model,solver=solver,shuffle=False):\n",
    "    solver = Solver(model,data_set,save_model=False,\n",
    "                    verbose=False,plot_graph=False)\n",
    "    #X_s,y_s = data_shuffler.sample(shuffle)\n",
    "    return solver.test_model(X_test[0:8*1024-1],y_test[0:8*1024-1])\n",
    "    #return solver.test_model(X_test[0:1024*6-1],y_test[0:1024*6-1])\n",
    "    #return solver.test_model(X_s,y_s)\n",
    "    #return solver.test_model(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Full percision model accuracy: 0.7024783492088318\n",
      "************Coarse search begin************\n",
      "Coarse seach done, compression rate:(0.25, 2146768),quantize model accuracy: 0.7008911967277527\n",
      "\n",
      "************Fine search begin************\n",
      "\n",
      "In compression search+++++++++++++++++++++++++++\n",
      "reduce wl on layer 14 kernel,acc_loss: 0.0040288567543029785, current accuracy:0.6984494924545288, compression rate: (0.24570703494741863, 2109904)\n",
      "<quantize_complier.WlflList object at 0x7f983d58d0a0>[[8,7,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][7,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,8,6]]\n",
      "Compression rate:0.24570703494741863\n",
      "Traget Compression rate:0.12\n",
      "------Fine tune the model------\n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.8289 - train_loss: 0.4826 - val_acc: NA    - val_loss: NA   \n",
      "In compression search+++++++++++++++++++++++++++\n",
      "reduce wl on layer 14 kernel,acc_loss: 0.0042729973793029785, current accuracy:0.6999145150184631, compression rate: (0.24141406989483727, 2073040)\n",
      "<quantize_complier.WlflList object at 0x7f983d58d0a0>[[8,7,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][6,7,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,8,6]]\n",
      "Compression rate:0.24141406989483727\n",
      "Traget Compression rate:0.12\n",
      "------Fine tune the model------\n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9026 - train_loss: 0.2921 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9277 - train_loss: 0.2232 - val_acc: NA    - val_loss: NA   \n",
      "In compression search+++++++++++++++++++++++++++\n",
      "reduce wl on layer 14 kernel,acc_loss: 0.03076547384262085, current accuracy:0.667439877986908, compression rate: (0.2371211048422559, 2036176)\n",
      "<quantize_complier.WlflList object at 0x7f983d58d0a0>[[8,7,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][5,7,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,8,6]]\n",
      "Compression rate:0.2371211048422559\n",
      "Traget Compression rate:0.12\n",
      "------Fine tune the model------\n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9421 - train_loss: 0.1648 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9287 - train_loss: 0.2048 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9485 - train_loss: 0.1576 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9457 - train_loss: 0.1650 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9401 - train_loss: 0.1788 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9587 - train_loss: 0.1293 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9591 - train_loss: 0.1215 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9619 - train_loss: 0.1141 - val_acc: NA    - val_loss: NA   \n",
      "!!!!!Can't Compress Any More!\n",
      "Start loss search++++++++++++++++++++++++++++\n",
      "reduce wl on layer 19 bias,acc_loss: -0.0001220703125, current accuracy:0.6811134219169617, compression rate: (0.2414129053535361, 2073030)\n",
      "<quantize_complier.WlflList object at 0x7f983d58d0a0>[[8,7,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][6,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,7,6]]\n",
      "<quantize_complier.AccuracyLossPerBitList object at 0x7f988152aac0>[[2.8270812890696106e-07,None][-2.6493540872252197e-07,None][5.300777772276888e-08,None][-5.298190686175985e-08,None][1.0598968458452873e-07,None][-2.6493540872252197e-07,None][-2.6493540872252197e-07,None][-2.6490953430879927e-08,None][-6.623385218063049e-08,None][1.0597674560131054e-07,None][-1.4571317308309517e-07,None][-9.272480383515358e-08,None][3.9742896973393727e-08,None][0.0,None][3.31185425750391e-08,None][-3.311369178859991e-09,None][2.6494186400327635e-08,None][-3.311369178859991e-09,None][-1.3247093200163818e-08,None][-7.630325740137778e-07,-1.220703143189894e-05]]\n",
      "reduce wl on layer 19 kernel,acc_loss: 0.0031742453575134277, current accuracy:0.6778171062469482, compression rate: (0.24133837471026212, 2072390)\n",
      "<quantize_complier.WlflList object at 0x7f983d58d0a0>[[8,7,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][6,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][7,8,7,5]]\n",
      "<quantize_complier.AccuracyLossPerBitList object at 0x7f988152aac0>[[8.478484687657328e-07,None][-1.5894572413799324e-07,None][1.0598968458452873e-07,None][1.589715878935749e-07,None][2.1195349120262108e-07,None][-3.1791731203156814e-07,None][-2.6493540872252197e-07,None][0.0,None][-7.947932800789204e-08,None][1.0597674560131054e-07,None][-1.4571317308309517e-07,None][-7.947932800789204e-08,None][5.298837280065527e-08,None][0.0,None][3.31185425750391e-08,None][-6.622738357719982e-09,None][3.31185425750391e-08,None][-3.311369178859991e-09,None][-1.3247093200163818e-08,None][-1.144502334682329e-06,3.662705421447754e-05]]\n",
      "------Fine tune the model------\n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9617 - train_loss: 0.1138 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9549 - train_loss: 0.1232 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9593 - train_loss: 0.1175 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9591 - train_loss: 0.1256 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9661 - train_loss: 0.0969 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9585 - train_loss: 0.1214 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9673 - train_loss: 0.1065 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9663 - train_loss: 0.1040 - val_acc: NA    - val_loss: NA   \n",
      "!!Loss seach end !!\n",
      "=========Finial Tunne=========\n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9651 - train_loss: 0.1080 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9718 - train_loss: 0.0882 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9653 - train_loss: 0.1044 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9730 - train_loss: 0.0887 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9643 - train_loss: 0.0963 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9573 - train_loss: 0.1336 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9643 - train_loss: 0.1144 - val_acc: NA    - val_loss: NA   \n",
      "Epoch: 0/1\n",
      "  156/1531 |==***********************|  - train_acc: 0.9700 - train_loss: 0.0943 - val_acc: NA    - val_loss: NA   \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<qunatize_resnet20.Resnet20 at 0x7f9882c47190>,\n",
       " <quantize_complier.WlflList at 0x7f983d58d0a0>)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "q_complier = qc.QunatizeComplier(model_q,full_model,q_layers,train_fn,test_fn,verbose=True,target_compression=0.12,max_loss=0.005)\n",
    "q_complier.quantize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: complier_tmp/3deep_compressed_resnet20_model/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_save_path = 'complier_tmp/3deep_compressed_resnet20_model'\n",
    "wlfl_save_path = 'complier_tmp/3deep_compressed_resnet20_wlfl.txt'\n",
    "model_q.model.save_weights(model_save_path)\n",
    "tf.saved_model.save(model_q.model,model_save_path)\n",
    "q_complier.wl_agent.get_wl_list().save(wlfl_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 1.796088457107544,Test Accuracy: 66.5199966430664\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.2414129053535361, 2073030)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "\n",
    "model_q.model.load_weights(model_save_path)\n",
    "q_layers = model_q.get_quantizable_layers()\n",
    "wlfl_list = qc.WlflList(len(q_layers))\n",
    "wlfl_list.load(wlfl_save_path)\n",
    "q_complier.fl_agent.apply_wlfl_to_layers(q_layers,wlfl_list)\n",
    "solver = Solver(model_q,data_set,train_options)\n",
    "solver.test_model(X_test,y_test)\n",
    "q_complier.wl_agent.get_compression_rate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 1.796088457107544,Test Accuracy: 66.5199966430664\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1.7960885>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.6652>)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "solver.test_model(X_test,y_test)"
   ]
  }
 ]
}