{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd01e176acbd42c1e3e7f101af43ec62a5c4debfebb92accde047567277d89b2ce2",
   "display_name": "Python 3.8.10 64-bit ('tf-gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,) int64\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gzip, shutil\n",
    "import os \n",
    "import data_utils as du \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import numpy as np \n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.pyplot import imread\n",
    "import matplotlib.pyplot as plt \n",
    "import platform\n",
    "import data_utils as du \n",
    "from cnn_model import *\n",
    "from solver import Solver\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "plt.rcParams['figure.figsize'] = (15.0, 15.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "Data_folder = 'CIFAR10_Data'\n",
    "Data_fn = 'cifar-10-python'\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = du.get_CIFAR10_data(subtract_mean =True)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ModelQunatize.to_fix_fn of <quantize_layers.ModelQunatize object at 0x7f4f58611130>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ModelQunatize.to_fix_fn of <quantize_layers.ModelQunatize object at 0x7f4f58611130>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "import qunatize_resnet20 as q_res\n",
    "import quantize_layers as ql\n",
    "data_set = {\n",
    "    'train_data': X_train,\n",
    "    'train_label': y_train,\n",
    "    'val_data':X_val,\n",
    "    'val_label':y_val,\n",
    "}\n",
    "train_options = {\n",
    "    'optimizer': 'adam',\n",
    "    'lr': 0.001,\n",
    "    'epoch_num': 20,\n",
    "    'from_logits':True,\n",
    "    'save_dir': 'resnet20_model'\n",
    "}\n",
    "qunatizer = ql.ModelQunatize() \n",
    "q_res20_model = q_res.Resnet20(quantizer=qunatizer)\n",
    "\n",
    "solver = Solver(q_res20_model,data_set,train_options,save_model=True)\n",
    "#solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 2022.33154296875,Test Accuracy: 9.949999809265137\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=2022.3315>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0995>)"
      ]
     },
     "metadata": {},
     "execution_count": 239
    }
   ],
   "source": [
    "solver.test_model(X_test,y_test)"
   ]
  },
  {
   "source": [
    "## Show layers and quantizable layers "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub \n",
    "import quantize_util as qu \n",
    "#prepare quntize model model_q\n",
    "qunatizer = ql.ModelQunatize()\n",
    "model_path = 'resnet20_model/trained_15'\n",
    "full_model = hub.KerasLayer(model_path,trainable=True)\n",
    "model_q = q_res.Resnet20(qunatizer)\n",
    "qu.copy_weight(model_q,full_model)\n",
    "\n",
    "train_options = {\n",
    "    'optimizer': 'adam',\n",
    "    'lr': 0.001,\n",
    "    'epoch_num': 20,\n",
    "    'from_logits':True,\n",
    "    'save_dir': 'resnet20_model'\n",
    "}\n",
    "solver = Solver(model_q,data_set,train_options,save_model=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy in full precision mode:\n",
      "Loss: 0.9363390803337097,Test Accuracy: 69.91000366210938\n",
      "Accuracy in wlfl mode:\n",
      "Loss: 0.9290823936462402,Test Accuracy: 69.41000366210938\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.9290824>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.6941>)"
      ]
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "source": [
    "solver = Solver(model_q,data_set,train_options,save_model=True)\n",
    "q_layer_num = model_q.get_quantizable_layer_count() \n",
    "wlfl_list = [[12,4]]*20\n",
    "qunatizer.set_wlfl_list(wlfl_list)\n",
    "qunatizer.set_full_precision_mode()\n",
    "print('Accuracy in full precision mode:')\n",
    "solver.test_model(X_test,y_test)\n",
    "\n",
    "print('Accuracy in wlfl mode:')\n",
    "qunatizer.set_quantize_mode()\n",
    "solver.test_model(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Test on quantize_var function "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n"
     ]
    }
   ],
   "source": [
    "wl = 16\n",
    "fl = 8\n",
    "quantizable_layers = model_q.get_quantizable_layers() \n",
    "for layer in quantizable_layers:\n",
    "    cur_layer = layer\n",
    "    for var in cur_layer.trainable_variables:\n",
    "        qu.quantize_var(var,wl,fl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy in full precision mode:\n",
      "Loss: 0.9395156502723694,Test Accuracy: 69.94000244140625\n",
      "Accuracy in wlfl mode:\n",
      "Loss: 0.9318090081214905,Test Accuracy: 69.43000030517578\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.931809>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.6943>)"
      ]
     },
     "metadata": {},
     "execution_count": 243
    }
   ],
   "source": [
    "qunatizer.set_wlfl_list(wlfl_list)\n",
    "qunatizer.set_full_precision_mode()\n",
    "print('Accuracy in full precision mode:')\n",
    "solver.test_model(X_test,y_test)\n",
    "\n",
    "print('Accuracy in wlfl mode:')\n",
    "qunatizer.set_quantize_mode()\n",
    "solver.test_model(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(-126.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "var = -125.999\n",
    "var = qu.to_fixpoint(var,10,2)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "quantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\n<quantize_layers.quantizeConv2D object at 0x7f4f587cf3d0>\n<quantize_layers.quantizeConv2D object at 0x7f4d5076d8b0>\n<quantize_layers.quantizeConv2D object at 0x7f4d50790ee0>\n<quantize_layers.quantizeConv2D object at 0x7f4d5fba7670>\n<quantize_layers.quantizeConv2D object at 0x7f4d5f85a790>\n<quantize_layers.quantizeConv2D object at 0x7f4d50424ca0>\n<quantize_layers.quantizeConv2D object at 0x7f4d50765ee0>\n<quantize_layers.quantizeConv2D object at 0x7f4d503dc6a0>\n<quantize_layers.quantizeConv2D object at 0x7f5020278880>\n<quantize_layers.quantizeConv2D object at 0x7f4f58d81d60>\n<quantize_layers.quantizeConv2D object at 0x7f4d6c3f9be0>\n<quantize_layers.quantizeConv2D object at 0x7f4f5a1ccd90>\n<quantize_layers.quantizeConv2D object at 0x7f4f587bf4c0>\n<quantize_layers.quantizeConv2D object at 0x7f4d5f855ca0>\n<quantize_layers.quantizeConv2D object at 0x7f4d514e5bb0>\n<quantize_layers.quantizeConv2D object at 0x7f4d503d7b50>\n<quantize_layers.quantizeConv2D object at 0x7f4d5150c0d0>\n<quantize_layers.quantizeConv2D object at 0x7f4f58bd1910>\n<quantize_layers.quantizeConv2D object at 0x7f4d5fa24e50>\n<quantize_layers.quantizeDense object at 0x7f4d514fbf70>\n<tf.Variable 'quantize_conv2d_798/kernel:0' shape=(3, 3, 3, 16) dtype=float32, numpy=\narray([[[[-0.0390625 ,  0.03125   ,  0.08203125,  0.4375    ,\n          -0.30859375,  0.25      , -0.04296875, -0.3125    ,\n           0.01953125, -0.453125  , -0.03125   ,  0.078125  ,\n           0.265625  ,  0.0234375 , -0.34765625,  0.22265625],\n         [-0.23828125, -0.16015625,  0.01171875, -0.50390625,\n           0.40234375, -0.01953125,  0.3984375 ,  0.0078125 ,\n          -0.3125    ,  0.03515625,  0.10546875, -0.42578125,\n           0.01953125,  0.19921875, -0.20703125, -0.01171875],\n         [ 0.36328125,  0.125     , -0.125     , -0.0234375 ,\n           0.078125  , -0.12890625, -0.14453125, -0.17578125,\n           0.19921875,  0.08984375, -0.1796875 ,  0.02734375,\n           0.0625    ,  0.0234375 , -0.15625   ,  0.16796875]],\n\n        [[-0.265625  ,  0.10546875,  0.00390625,  0.1640625 ,\n           0.18359375, -0.26953125, -0.02734375, -0.015625  ,\n           0.04296875, -0.2109375 , -0.0703125 ,  0.09375   ,\n          -0.3046875 ,  0.00390625,  0.08203125,  0.25390625],\n         [ 0.51953125,  0.1953125 , -0.078125  , -0.10546875,\n           0.1484375 ,  0.16015625, -0.0078125 ,  0.05078125,\n          -0.1015625 ,  0.03515625, -0.19921875,  0.328125  ,\n           0.3203125 ,  0.30078125,  0.4765625 , -0.30859375],\n         [ 0.15234375,  0.015625  ,  0.1171875 ,  0.1328125 ,\n          -0.44921875,  0.1015625 ,  0.21484375, -0.34765625,\n          -0.23828125,  0.34765625, -0.35546875,  0.546875  ,\n          -0.0546875 , -0.30859375,  0.1171875 , -0.18359375]],\n\n        [[-0.0078125 ,  0.11328125, -0.47265625,  0.234375  ,\n          -0.234375  , -0.20703125, -0.265625  ,  0.1015625 ,\n          -0.0390625 , -0.2578125 , -0.1875    ,  0.5625    ,\n           0.4453125 ,  0.44140625,  0.203125  , -0.14453125],\n         [-0.45703125, -0.1953125 , -0.07421875, -0.1640625 ,\n          -0.14453125, -0.35546875,  0.1328125 ,  0.265625  ,\n           0.140625  , -0.2421875 , -0.22265625,  0.4140625 ,\n          -0.16796875,  0.02734375, -0.23046875, -0.109375  ],\n         [ 0.12890625, -0.1796875 ,  0.16015625, -0.08984375,\n           0.1796875 , -0.20703125,  0.27734375,  0.125     ,\n          -0.0078125 ,  0.3359375 ,  0.3203125 , -0.078125  ,\n          -0.16796875,  0.125     , -0.0078125 , -0.171875  ]]],\n\n\n       [[[-0.375     , -0.6171875 ,  0.375     , -0.11328125,\n          -0.3046875 ,  0.44921875,  0.14453125,  0.09765625,\n          -0.09765625, -0.30859375, -0.21875   , -0.515625  ,\n          -0.078125  ,  0.37890625,  0.02734375,  0.32421875],\n         [ 0.5546875 ,  0.15234375, -0.21875   , -0.1015625 ,\n           0.41796875, -0.09765625,  0.        , -0.24609375,\n           0.04296875, -0.03125   , -0.34375   , -0.3125    ,\n          -0.16015625, -0.43359375, -0.4921875 , -0.21875   ],\n         [-0.328125  ,  0.        ,  0.1875    , -0.20703125,\n          -0.34765625,  0.4296875 , -0.16015625,  0.046875  ,\n           0.2578125 ,  0.0625    ,  0.140625  ,  0.16796875,\n           0.08984375,  0.0625    , -0.0703125 , -0.09765625]],\n\n        [[-0.02734375, -0.53515625,  0.20703125,  0.12109375,\n          -0.09375   , -0.42578125, -0.19140625, -0.1796875 ,\n           0.0859375 ,  0.3203125 , -0.03125   , -0.46484375,\n           0.515625  ,  0.27734375, -0.21484375,  0.21484375],\n         [ 0.46484375,  0.5390625 , -0.41796875,  0.49609375,\n           0.34375   ,  0.2578125 ,  0.26953125,  0.5546875 ,\n          -0.046875  , -0.13671875, -0.0546875 ,  0.13671875,\n          -0.26171875, -0.25      ,  0.5390625 ,  0.09375   ],\n         [-0.05859375, -0.28515625, -0.37890625,  0.1875    ,\n          -0.22265625, -0.55859375, -0.14453125,  0.25390625,\n          -0.0859375 ,  0.25390625, -0.08984375,  0.28125   ,\n          -0.06640625,  0.03125   , -0.03515625,  0.34375   ]],\n\n        [[ 0.2421875 , -0.03125   ,  0.43359375, -0.1640625 ,\n           0.0703125 , -0.45703125, -0.08203125, -0.625     ,\n           0.1015625 , -0.31640625,  0.3984375 , -0.40234375,\n          -0.25      ,  0.56640625,  0.51953125,  0.05078125],\n         [-0.1875    ,  0.203125  , -0.5       , -0.01953125,\n          -0.12890625,  0.0390625 , -0.25      ,  0.35546875,\n          -0.0703125 , -0.08203125, -0.078125  , -0.12890625,\n          -0.7421875 , -0.26171875, -0.046875  ,  0.34765625],\n         [-0.5078125 , -0.15625   ,  0.3203125 , -0.28125   ,\n          -0.140625  ,  0.06640625,  0.03125   , -0.1484375 ,\n           0.17578125,  0.29296875,  0.1875    , -0.515625  ,\n          -0.12890625, -0.44921875, -0.0078125 , -0.05859375]]],\n\n\n       [[[-0.40625   , -0.01171875, -0.12890625,  0.49609375,\n          -0.5234375 ,  0.0625    , -0.4453125 , -0.1953125 ,\n          -0.26171875,  0.03515625,  0.0859375 , -0.125     ,\n          -0.01171875, -0.14453125, -0.1484375 , -0.0078125 ],\n         [-0.44921875, -0.234375  , -0.29296875,  0.55859375,\n           0.62109375, -0.12109375, -0.30859375,  0.04296875,\n          -0.11328125, -0.296875  ,  0.078125  ,  0.22265625,\n           0.3515625 ,  0.06640625,  0.296875  , -0.21875   ],\n         [ 0.0390625 ,  0.6171875 , -0.0390625 ,  0.51171875,\n          -0.29296875, -0.09765625,  0.171875  ,  0.07421875,\n          -0.1796875 ,  0.2265625 , -0.26953125,  0.08203125,\n          -0.05859375, -0.19921875,  0.39453125,  0.109375  ]],\n\n        [[ 0.09375   ,  0.12890625,  0.2578125 , -0.12109375,\n           0.43359375, -0.390625  ,  0.234375  , -0.0703125 ,\n           0.07421875, -0.0078125 ,  0.265625  ,  0.10546875,\n           0.00390625, -0.421875  , -0.0234375 , -0.046875  ],\n         [-0.01171875, -0.2265625 , -0.54296875, -0.16015625,\n           0.1015625 ,  0.515625  , -0.12890625,  0.1796875 ,\n          -0.12109375,  0.1875    ,  0.14453125, -0.34375   ,\n           0.35546875, -0.48046875, -0.4453125 , -0.05078125],\n         [-0.015625  , -0.0703125 ,  0.5078125 ,  0.13671875,\n          -0.1171875 , -0.05078125,  0.08984375, -0.171875  ,\n          -0.1328125 ,  0.21875   , -0.140625  ,  0.3046875 ,\n           0.46484375, -0.3984375 ,  0.25      ,  0.48828125]],\n\n        [[ 0.00390625,  0.33203125,  0.13671875, -0.19140625,\n           0.18359375,  0.46484375, -0.21484375,  0.03125   ,\n           0.640625  , -0.23828125,  0.2109375 , -0.40625   ,\n          -0.43359375, -0.1328125 , -0.09375   , -0.6484375 ],\n         [-0.24609375,  0.12890625,  0.171875  , -0.3203125 ,\n           0.1171875 , -0.05859375,  0.453125  ,  0.2890625 ,\n           0.39453125, -0.19140625,  0.1484375 ,  0.140625  ,\n          -0.14453125,  0.27734375,  0.0625    ,  0.08984375],\n         [ 0.5234375 , -0.2109375 , -0.02734375, -0.27734375,\n          -0.2109375 ,  0.21875   ,  0.28515625,  0.15625   ,\n           0.25      ,  0.45703125,  0.1796875 ,  0.0859375 ,\n          -0.0078125 ,  0.33203125, -0.33984375,  0.26171875]]]],\n      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "q_layers = model_q.get_quantizable_layers()\n",
    "for layer in q_layers:\n",
    "    #print(layer[0].kernel)\n",
    "    print(layer)\n",
    "a = np.abs(q_layers[0].kernel.numpy())\n",
    "#print(a.reshape(-1))\n",
    "c = a.reshape(-1).shape[0]\n",
    "print(q_layers[0].kernel)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Test WLsearch agent "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Test get_parameter_size \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "quantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nquantize layer extracting\nTotal trainable parameter: (268346, [[432, 0], [2304, 0], [2304, 0], [2304, 0], [2304, 0], [2304, 0], [2304, 0], [4608, 0], [9216, 0], [9216, 0], [9216, 0], [9216, 0], [9216, 0], [18432, 0], [36864, 0], [36864, 0], [36864, 0], [36864, 0], [36864, 0], [640, 10]])\n=============================\n20\n32\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "import quantize_complier as qc \n",
    "q_layers = model_q.get_quantizable_layers()\n",
    "wl_agent = qc.WLSearchAgent(model_q,q_layers)\n",
    "total_size = wl_agent.get_parameter_size()\n",
    "total_size = total_size\n",
    "print('Total trainable parameter: {}'.format(total_size))\n",
    "q_layers_copy = q_layers\n",
    "q_data = q_layers[0].kernel \n",
    "\n",
    "#print(q_layers[0].kernel)\n",
    "print('=============================')\n",
    "#print(q_data)\n",
    "print(len(wl_agent.layers_param_list))\n",
    "print(wl_agent.wl_list.layer(15).kernel_wl)\n",
    "wl_agent.get_intger_bits(-3)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Test init_search and compression_rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<quantize_complier.WlflList object at 0x7f4d504386d0>[8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,8,16]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.25, 2146768)"
      ]
     },
     "metadata": {},
     "execution_count": 247
    }
   ],
   "source": [
    "wl_agent.init_search()\n",
    "print(wl_agent.wl_list)\n",
    "wl_agent.get_compression_rate()"
   ]
  },
  {
   "source": [],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Test SerachFL agent "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Test search_layer_fl"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20\n",
      "20\n",
      "<quantize_complier.WlflList object at 0x7f4d504386d0>[8,7,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,0,0][8,8,8,7]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 10), dtype=float32, numpy=\n",
       "array([[ -1.1140418 ,  -3.0844963 ,  -0.19119889, ...,  -3.4918647 ,\n",
       "          3.9700978 ,  -3.0854871 ],\n",
       "       [  3.0226173 ,   7.9003086 ,  -3.0500617 , ..., -10.4363    ,\n",
       "         10.445696  ,   0.5678308 ],\n",
       "       [  3.4073093 ,  -1.6375792 ,  -1.2897418 , ...,  -1.7099354 ,\n",
       "          4.972007  ,  -1.7667176 ],\n",
       "       ...,\n",
       "       [ -3.7454298 ,  -5.1136103 ,  10.919554  , ...,   1.1329545 ,\n",
       "         -3.4651012 ,  -7.9818344 ],\n",
       "       [  2.680488  ,   8.803678  ,   1.5420569 , ...,  -7.6888943 ,\n",
       "         -2.824695  ,   2.2716513 ],\n",
       "       [ -0.6138832 ,  -7.2697687 ,   1.4499471 , ...,  11.590846  ,\n",
       "         -3.1202664 ,  -6.6720796 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 248
    }
   ],
   "source": [
    "#q_layers = wl_agent.get_quantize_layers()\n",
    "\n",
    "data_set = {\n",
    "    'train_data': X_train,\n",
    "    'train_label': y_train,\n",
    "    'val_data':X_val,\n",
    "    'val_label':y_val,\n",
    "}\n",
    "train_options = {\n",
    "    'optimizer': 'adam',\n",
    "    'lr': 0.001,\n",
    "    'epoch_num': 20,\n",
    "    'from_logits':True,\n",
    "    'save_dir': 'resnet20_model'\n",
    "}\n",
    "def acc_fn(model):\n",
    "    solver = Solver(model_q,data_set,save_model=False)\n",
    "    solver.test_model(X_test,y_test)\n",
    "fl_agent = qc.FlSerachAgent(model_q,solver,acc_fn)\n",
    "print(len(wl_agent.get_wl_list()))\n",
    "print(len(q_layers))\n",
    "fl_agent.search_layers_fl(q_layers,wl_agent.get_wl_list())\n",
    "print(wl_agent.get_wl_list())\n",
    "fl_agent.apply_wlfl_to_layers(q_layers,wl_agent.get_wl_list())\n",
    "#fl_agent.model_accuracy()\n",
    "#solver.test_model(X_test,y_test)\n",
    "model_q(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "quantize layer extracting\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": []
  }
 ]
}