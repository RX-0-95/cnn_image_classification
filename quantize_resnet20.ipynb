{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd01e176acbd42c1e3e7f101af43ec62a5c4debfebb92accde047567277d89b2ce2",
   "display_name": "Python 3.8.10 64-bit ('tf-gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,) int64\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gzip, shutil\n",
    "import os \n",
    "import data_utils as du \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import numpy as np \n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.pyplot import imread\n",
    "import matplotlib.pyplot as plt \n",
    "import platform\n",
    "import data_utils as du \n",
    "from cnn_model import *\n",
    "from solver import Solver\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "plt.rcParams['figure.figsize'] = (15.0, 15.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "Data_folder = 'CIFAR10_Data'\n",
    "Data_fn = 'cifar-10-python'\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = du.get_CIFAR10_data(subtract_mean =True)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qunatize_resnet20 as q_res\n",
    "import quantize_layers as ql\n",
    "data_set = {\n",
    "    'train_data': X_train,\n",
    "    'train_label': y_train,\n",
    "    'val_data':X_val,\n",
    "    'val_label':y_val,\n",
    "}\n",
    "train_options = {\n",
    "    'optimizer': 'adam',\n",
    "    'lr': 0.001,\n",
    "    'epoch_num': 20,\n",
    "    'from_logits':True,\n",
    "    'save_dir': 'resnet20_model'\n",
    "}\n",
    "qunatizer = ql.ModelQunatize() \n",
    "q_res20_model = q_res.Resnet20(quantizer=qunatizer)\n",
    "\n",
    "solver = Solver(q_res20_model,data_set,train_options,save_model=True)\n",
    "#solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 4896.486328125,Test Accuracy: 10.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=4896.4863>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.1>)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "solver.test_model(X_test,y_test)"
   ]
  },
  {
   "source": [
    "## Show layers and quantizable layers "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub \n",
    "import quantize_util as qu \n",
    "#prepare quntize model model_q\n",
    "qunatizer = ql.ModelQunatize()\n",
    "model_path = 'resnet20_model/trained_15'\n",
    "full_model = hub.KerasLayer(model_path,trainable=True)\n",
    "model_q = q_res.Resnet20(qunatizer)\n",
    "qu.copy_weight(model_q,full_model)\n",
    "\n",
    "train_options = {\n",
    "    'optimizer': 'adam',\n",
    "    'lr': 0.001,\n",
    "    'epoch_num': 20,\n",
    "    'from_logits':True,\n",
    "    'save_dir': 'resnet20_model'\n",
    "}\n",
    "solver = Solver(model_q,data_set,train_options,save_model=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy in full precision mode:\n",
      "Loss: 0.9363390803337097,Test Accuracy: 69.91000366210938\n",
      "Accuracy in wlfl mode:\n",
      "Loss: 0.9290823936462402,Test Accuracy: 69.41000366210938\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.9290824>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.6941>)"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "solver = Solver(model_q,data_set,train_options,save_model=True)\n",
    "q_layer_num = model_q.get_quantizable_layer_count() \n",
    "wlfl_list = [[12,4]]*20\n",
    "qunatizer.set_wlfl_list(wlfl_list)\n",
    "qunatizer.set_full_precision_mode()\n",
    "print('Accuracy in full precision mode:')\n",
    "solver.test_model(X_test,y_test)\n",
    "\n",
    "print('Accuracy in wlfl mode:')\n",
    "qunatizer.set_quantize_mode()\n",
    "solver.test_model(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Test on quantize_var function "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = 16\n",
    "fl = 8\n",
    "quantizable_layers = model_q.get_quantizable_layers() \n",
    "for layer in quantizable_layers:\n",
    "    cur_layer = layer\n",
    "    for var in cur_layer.trainable_variables:\n",
    "        qu.quantize_var(var,wl,fl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy in full precision mode:\n",
      "Loss: 0.9395156502723694,Test Accuracy: 69.94000244140625\n",
      "Accuracy in wlfl mode:\n",
      "Loss: 0.9395156502723694,Test Accuracy: 69.94000244140625\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.93951565>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.6994>)"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "qunatizer.set_wlfl_list(wlfl_list)\n",
    "qunatizer.set_full_precision_mode()\n",
    "print('Accuracy in full precision mode:')\n",
    "solver.test_model(X_test,y_test)\n",
    "\n",
    "print('Accuracy in wlfl mode:')\n",
    "qunatizer.set_quantize_mode()\n",
    "solver.test_model(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(-126.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "var = -125.999\n",
    "var = qu.to_fixpoint(var,10,2)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<quantize_layers.quantizeConv2D object at 0x7f7c8f9973a0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f984130>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f9826d0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f994df0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f99a100>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f9909d0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f92c460>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f94ad00>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f98b610>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f8ebdf0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f8f9eb0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f90e7c0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f914dc0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f93ca90>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f984040>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f8b0fa0>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f8b0e80>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f8c6460>\n<quantize_layers.quantizeConv2D object at 0x7f7c8f8c7f40>\n<quantize_layers.quantizeDense object at 0x7f7c8f8df760>\n<tf.Variable 'quantize_conv2d_133/kernel:0' shape=(3, 3, 3, 16) dtype=float32, numpy=\narray([[[[-0.0390625 ,  0.03125   ,  0.08203125,  0.4375    ,\n          -0.30859375,  0.25      , -0.04296875, -0.3125    ,\n           0.01953125, -0.453125  , -0.03125   ,  0.078125  ,\n           0.265625  ,  0.0234375 , -0.34765625,  0.22265625],\n         [-0.23828125, -0.16015625,  0.01171875, -0.50390625,\n           0.40234375, -0.01953125,  0.3984375 ,  0.0078125 ,\n          -0.3125    ,  0.03515625,  0.10546875, -0.42578125,\n           0.01953125,  0.19921875, -0.20703125, -0.01171875],\n         [ 0.36328125,  0.125     , -0.125     , -0.0234375 ,\n           0.078125  , -0.12890625, -0.14453125, -0.17578125,\n           0.19921875,  0.08984375, -0.1796875 ,  0.02734375,\n           0.0625    ,  0.0234375 , -0.15625   ,  0.16796875]],\n\n        [[-0.265625  ,  0.10546875,  0.00390625,  0.1640625 ,\n           0.18359375, -0.26953125, -0.02734375, -0.015625  ,\n           0.04296875, -0.2109375 , -0.0703125 ,  0.09375   ,\n          -0.3046875 ,  0.00390625,  0.08203125,  0.25390625],\n         [ 0.51953125,  0.1953125 , -0.078125  , -0.10546875,\n           0.1484375 ,  0.16015625, -0.0078125 ,  0.05078125,\n          -0.1015625 ,  0.03515625, -0.19921875,  0.328125  ,\n           0.3203125 ,  0.30078125,  0.4765625 , -0.30859375],\n         [ 0.15234375,  0.015625  ,  0.1171875 ,  0.1328125 ,\n          -0.44921875,  0.1015625 ,  0.21484375, -0.34765625,\n          -0.23828125,  0.34765625, -0.35546875,  0.546875  ,\n          -0.0546875 , -0.30859375,  0.1171875 , -0.18359375]],\n\n        [[-0.0078125 ,  0.11328125, -0.47265625,  0.234375  ,\n          -0.234375  , -0.20703125, -0.265625  ,  0.1015625 ,\n          -0.0390625 , -0.2578125 , -0.1875    ,  0.5625    ,\n           0.4453125 ,  0.44140625,  0.203125  , -0.14453125],\n         [-0.45703125, -0.1953125 , -0.07421875, -0.1640625 ,\n          -0.14453125, -0.35546875,  0.1328125 ,  0.265625  ,\n           0.140625  , -0.2421875 , -0.22265625,  0.4140625 ,\n          -0.16796875,  0.02734375, -0.23046875, -0.109375  ],\n         [ 0.12890625, -0.1796875 ,  0.16015625, -0.08984375,\n           0.1796875 , -0.20703125,  0.27734375,  0.125     ,\n          -0.0078125 ,  0.3359375 ,  0.3203125 , -0.078125  ,\n          -0.16796875,  0.125     , -0.0078125 , -0.171875  ]]],\n\n\n       [[[-0.375     , -0.6171875 ,  0.375     , -0.11328125,\n          -0.3046875 ,  0.44921875,  0.14453125,  0.09765625,\n          -0.09765625, -0.30859375, -0.21875   , -0.515625  ,\n          -0.078125  ,  0.37890625,  0.02734375,  0.32421875],\n         [ 0.5546875 ,  0.15234375, -0.21875   , -0.1015625 ,\n           0.41796875, -0.09765625,  0.        , -0.24609375,\n           0.04296875, -0.03125   , -0.34375   , -0.3125    ,\n          -0.16015625, -0.43359375, -0.4921875 , -0.21875   ],\n         [-0.328125  ,  0.        ,  0.1875    , -0.20703125,\n          -0.34765625,  0.4296875 , -0.16015625,  0.046875  ,\n           0.2578125 ,  0.0625    ,  0.140625  ,  0.16796875,\n           0.08984375,  0.0625    , -0.0703125 , -0.09765625]],\n\n        [[-0.02734375, -0.53515625,  0.20703125,  0.12109375,\n          -0.09375   , -0.42578125, -0.19140625, -0.1796875 ,\n           0.0859375 ,  0.3203125 , -0.03125   , -0.46484375,\n           0.515625  ,  0.27734375, -0.21484375,  0.21484375],\n         [ 0.46484375,  0.5390625 , -0.41796875,  0.49609375,\n           0.34375   ,  0.2578125 ,  0.26953125,  0.5546875 ,\n          -0.046875  , -0.13671875, -0.0546875 ,  0.13671875,\n          -0.26171875, -0.25      ,  0.5390625 ,  0.09375   ],\n         [-0.05859375, -0.28515625, -0.37890625,  0.1875    ,\n          -0.22265625, -0.55859375, -0.14453125,  0.25390625,\n          -0.0859375 ,  0.25390625, -0.08984375,  0.28125   ,\n          -0.06640625,  0.03125   , -0.03515625,  0.34375   ]],\n\n        [[ 0.2421875 , -0.03125   ,  0.43359375, -0.1640625 ,\n           0.0703125 , -0.45703125, -0.08203125, -0.625     ,\n           0.1015625 , -0.31640625,  0.3984375 , -0.40234375,\n          -0.25      ,  0.56640625,  0.51953125,  0.05078125],\n         [-0.1875    ,  0.203125  , -0.5       , -0.01953125,\n          -0.12890625,  0.0390625 , -0.25      ,  0.35546875,\n          -0.0703125 , -0.08203125, -0.078125  , -0.12890625,\n          -0.7421875 , -0.26171875, -0.046875  ,  0.34765625],\n         [-0.5078125 , -0.15625   ,  0.3203125 , -0.28125   ,\n          -0.140625  ,  0.06640625,  0.03125   , -0.1484375 ,\n           0.17578125,  0.29296875,  0.1875    , -0.515625  ,\n          -0.12890625, -0.44921875, -0.0078125 , -0.05859375]]],\n\n\n       [[[-0.40625   , -0.01171875, -0.12890625,  0.49609375,\n          -0.5234375 ,  0.0625    , -0.4453125 , -0.1953125 ,\n          -0.26171875,  0.03515625,  0.0859375 , -0.125     ,\n          -0.01171875, -0.14453125, -0.1484375 , -0.0078125 ],\n         [-0.44921875, -0.234375  , -0.29296875,  0.55859375,\n           0.62109375, -0.12109375, -0.30859375,  0.04296875,\n          -0.11328125, -0.296875  ,  0.078125  ,  0.22265625,\n           0.3515625 ,  0.06640625,  0.296875  , -0.21875   ],\n         [ 0.0390625 ,  0.6171875 , -0.0390625 ,  0.51171875,\n          -0.29296875, -0.09765625,  0.171875  ,  0.07421875,\n          -0.1796875 ,  0.2265625 , -0.26953125,  0.08203125,\n          -0.05859375, -0.19921875,  0.39453125,  0.109375  ]],\n\n        [[ 0.09375   ,  0.12890625,  0.2578125 , -0.12109375,\n           0.43359375, -0.390625  ,  0.234375  , -0.0703125 ,\n           0.07421875, -0.0078125 ,  0.265625  ,  0.10546875,\n           0.00390625, -0.421875  , -0.0234375 , -0.046875  ],\n         [-0.01171875, -0.2265625 , -0.54296875, -0.16015625,\n           0.1015625 ,  0.515625  , -0.12890625,  0.1796875 ,\n          -0.12109375,  0.1875    ,  0.14453125, -0.34375   ,\n           0.35546875, -0.48046875, -0.4453125 , -0.05078125],\n         [-0.015625  , -0.0703125 ,  0.5078125 ,  0.13671875,\n          -0.1171875 , -0.05078125,  0.08984375, -0.171875  ,\n          -0.1328125 ,  0.21875   , -0.140625  ,  0.3046875 ,\n           0.46484375, -0.3984375 ,  0.25      ,  0.48828125]],\n\n        [[ 0.00390625,  0.33203125,  0.13671875, -0.19140625,\n           0.18359375,  0.46484375, -0.21484375,  0.03125   ,\n           0.640625  , -0.23828125,  0.2109375 , -0.40625   ,\n          -0.43359375, -0.1328125 , -0.09375   , -0.6484375 ],\n         [-0.24609375,  0.12890625,  0.171875  , -0.3203125 ,\n           0.1171875 , -0.05859375,  0.453125  ,  0.2890625 ,\n           0.39453125, -0.19140625,  0.1484375 ,  0.140625  ,\n          -0.14453125,  0.27734375,  0.0625    ,  0.08984375],\n         [ 0.5234375 , -0.2109375 , -0.02734375, -0.27734375,\n          -0.2109375 ,  0.21875   ,  0.28515625,  0.15625   ,\n           0.25      ,  0.45703125,  0.1796875 ,  0.0859375 ,\n          -0.0078125 ,  0.33203125, -0.33984375,  0.26171875]]]],\n      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "q_layers = model_q.get_quantizable_layers()\n",
    "for layer in q_layers:\n",
    "    #print(layer[0].kernel)\n",
    "    print(layer)\n",
    "a = np.abs(q_layers[0].kernel.numpy())\n",
    "#print(a.reshape(-1))\n",
    "c = a.reshape(-1).shape[0]\n",
    "print(q_layers[0].kernel)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Test WLsearch agent "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Test get_parameter_size \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total trainable parameter: (268346, [[432, 0], [2304, 0], [2304, 0], [2304, 0], [2304, 0], [2304, 0], [2304, 0], [4608, 0], [9216, 0], [9216, 0], [9216, 0], [9216, 0], [9216, 0], [18432, 0], [36864, 0], [36864, 0], [36864, 0], [36864, 0], [36864, 0], [640, 10]])\n=============================\n20\n32\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "import quantize_complier as qc \n",
    "q_layers = model_q.get_quantizable_layers()\n",
    "wl_agent = qc.WLSearchAgent(model_q,q_layers)\n",
    "total_size = wl_agent.get_parameter_size()\n",
    "total_size = total_size\n",
    "print('Total trainable parameter: {}'.format(total_size))\n",
    "q_layers_copy = q_layers\n",
    "q_data = q_layers[0].kernel \n",
    "\n",
    "#print(q_layers[0].kernel)\n",
    "print('=============================')\n",
    "#print(q_data)\n",
    "print(len(wl_agent.layers_param_list))\n",
    "print(wl_agent.wl_list.layer(15).kernel_wl)\n",
    "wl_agent.get_intger_bits(-3)\n"
   ]
  },
  {
   "source": [
    "### Test init_search and compression_rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<quantize_complier.WlflList object at 0x7f7c8f880e20>[8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,0,16][8,16,8,16]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.25, 2146768)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "wl_agent.init_search()\n",
    "print(wl_agent.wl_list)\n",
    "wl_agent.get_compression_rate()"
   ]
  },
  {
   "source": [
    "solver.test_model(X_test,y_test)\n",
    "qu.quantize_weights_bias(model_q,7,6,7,6)\n",
    "solver.test_model(X_test,y_test)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 2.7540268898010254,Test Accuracy: 13.649999618530273\n",
      "Loss: 2.7540268898010254,Test Accuracy: 13.649999618530273\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=2.754027>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.1365>)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ]
  }
 ]
}